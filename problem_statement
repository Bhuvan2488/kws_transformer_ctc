Problem Statement — Keyword Spotting (KWS) Word Alignment

Audio recordings lo spoken words ki exact start–end timestamps automatically extract cheyyadam tough, manual annotation costly & slow.
Given audio files + word-level annotations (train time only), the goal is to frame-level word alignment model train chesi, new audio lo each word ekkada start/stop ayyindo high accuracy tho predict cheyyadam.

Objectives:

Raw audio ni frame-level log-mel features ga convert cheyyadam

Word annotations ni frame-level labels ga map cheyyadam

Transformer-based sequence model train chesi frame-wise word classification cheyyadam

Predicted frames ni continuous word segments + timestamps ga convert cheyyadam

Ground-truth tho compare chesi alignment accuracy evaluate cheyyadam

Constraints & Challenges:

Variable-length audio sequences

Silence vs speech handling (BLANK class)

Precise time-to-frame mapping

Overlapping / close word boundaries

Efficient padding & masking for Transformers

Expected Outcome:

Each audio file ki:
[{ word, start_time, end_time }]

Mean / median alignment error seconds lo minimize avvali

Scalable pipeline: preprocess → train → infer → evaluate
