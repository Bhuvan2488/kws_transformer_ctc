{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586dc455",
   "metadata": {},
   "source": [
    "# KWS MODEL\n",
    "\n",
    "## **STEP 1 — DATA INGESTION**\n",
    "\n",
    "**PURPOSE:** Load audio + annotation pairs using the same base filename.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "* `data/raw/audio/*.wav`\n",
    "* `data/raw/annotations/*_Annotated.txt`\n",
    "\n",
    "**Process:**\n",
    "\n",
    "* Match `sample_id.wav` ↔ `sample_id_Annotated.txt`\n",
    "* Build sample list from `data/splits/{train,val,test}.txt`\n",
    "\n",
    "**Code written in:**\n",
    "\n",
    "* `src/data/audio_loader.py`\n",
    "* `src/data/annotation_loader.py`\n",
    "\n",
    "**Output (artifact):**\n",
    "\n",
    "* In-memory sample index (IDs ready for preprocessing)\n",
    "\n",
    "**Validation check:**\n",
    "\n",
    "* For every ID in split file → audio + annotation file exists\n",
    "\n",
    "---\n",
    "\n",
    "## **STEP 2 — DATA VALIDATION**\n",
    "\n",
    "**PURPOSE:** Remove invalid samples using strict annotation rule.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "* `data/raw/annotations/*_Annotated.txt`\n",
    "\n",
    "**Process:**\n",
    "\n",
    "* If annotation contains `#` → discard sample (do not use)\n",
    "\n",
    "**Code written in:**\n",
    "\n",
    "* `src/data/clean.py`\n",
    "\n",
    "**Output (artifact):**\n",
    "\n",
    "* Clean sample list (valid IDs only)\n",
    "\n",
    "**Validation check:**\n",
    "\n",
    "* Count valid vs invalid samples printed in logs\n",
    "\n",
    "---\n",
    "\n",
    "## **STEP 3 — FEATURE EXTRACTION**\n",
    "\n",
    "**PURPOSE:** Convert audio into log-mel features for Transformer input.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "* `data/raw/audio/*.wav`\n",
    "\n",
    "**Process:**\n",
    "\n",
    "* Load waveform\n",
    "* Extract **log-mel spectrogram**\n",
    "* Normalize features\n",
    "\n",
    "**Code written in:**\n",
    "\n",
    "* `src/data/feature_extraction.py`\n",
    "\n",
    "**Output (artifact):**\n",
    "\n",
    "* `data/processed/features/{sample_id}.npy`  *(shape: T×80 float32)*\n",
    "\n",
    "**Validation check:**\n",
    "\n",
    "* `.npy` loads successfully and has expected shape `(T, 80)`\n",
    "\n",
    "---\n",
    "\n",
    "## **STEP 4 — FRAME LABEL GENERATION (FROM ANNOTATIONS)**\n",
    "\n",
    "**PURPOSE:** Convert word timestamps into **frame-wise labels** for supervision.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "* `data/raw/annotations/{sample_id}_Annotated.txt` *(Audacity format: start, end, word)*\n",
    "* `data/processed/features/{sample_id}.npy` *(to get total frames T)*\n",
    "\n",
    "**Process:**\n",
    "\n",
    "* Parse each line: `start_time  end_time  WORD`\n",
    "* Convert seconds → frame index using:\n",
    "  `frame = time * sample_rate / hop_length`\n",
    "* Create label array length `T`:\n",
    "\n",
    "  * `BLANK` for non-word frames\n",
    "  * `WORD_ID` for frames inside word segments\n",
    "\n",
    "**Code written in:**\n",
    "\n",
    "* `src/data/label_builder.py`\n",
    "\n",
    "**Output (artifacts):**\n",
    "\n",
    "* `data/processed/frame_labels/{sample_id}.npy` *(shape: T, int64)*\n",
    "* `data/processed/frame_labels/label_map.json` *(word → id mapping)*\n",
    "\n",
    "**Validation check:**\n",
    "\n",
    "* `len(frame_labels) == T` (matches feature frames exactly)\n",
    "\n",
    "---\n",
    "\n",
    "## **STEP 5 — DATASET PREPARATION**\n",
    "\n",
    "**PURPOSE:** Load features + frame labels in a training-ready PyTorch format.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "* `data/processed/features/*.npy`\n",
    "* `data/processed/frame_labels/*.npy`\n",
    "* `data/splits/{train,val,test}.txt`\n",
    "\n",
    "**Process:**\n",
    "\n",
    "* Load `(features, frame_labels)` per sample\n",
    "* Pad sequences in batch\n",
    "* Create masks and lengths\n",
    "\n",
    "**Code written in:**\n",
    "\n",
    "* `src/data/dataset.py`\n",
    "\n",
    "**Output (artifact):**\n",
    "\n",
    "* Dataloader batches:\n",
    "\n",
    "  * `x: (B, T, 80)`\n",
    "  * `y: (B, T)`\n",
    "  * `lengths: (B,)`\n",
    "\n",
    "**Validation check:**\n",
    "\n",
    "* One batch prints correct shapes and no mismatch errors\n",
    "\n",
    "---\n",
    "\n",
    "## **STEP 6 — MODEL ARCHITECTURE**\n",
    "\n",
    "**PURPOSE:** Build model that predicts a class for every frame.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "* `x: (B, T, 80)` features\n",
    "* `num_classes = BLANK + word_vocab_size`\n",
    "\n",
    "**Process:**\n",
    "\n",
    "* Transformer Encoder processes frames\n",
    "* Linear head outputs logits per frame\n",
    "\n",
    "**Code written in:**\n",
    "\n",
    "* `src/model/transformer_encoder.py`\n",
    "* `src/model/frame_classifier.py`\n",
    "* `src/model/model.py`\n",
    "\n",
    "**Output (artifact):**\n",
    "\n",
    "* Logits: `logits: (B, T, num_classes)`\n",
    "\n",
    "**Validation check:**\n",
    "\n",
    "* Forward pass works on one batch without crashing\n",
    "\n",
    "---\n",
    "\n",
    "## **STEP 7 — TRAINING (FRAME SUPERVISED)**\n",
    "\n",
    "**PURPOSE:** Train Transformer to classify frame labels using annotations.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "* Training DataLoader from Step 5\n",
    "* Model from Step 6\n",
    "\n",
    "**Process:**\n",
    "\n",
    "* Compute logits\n",
    "* Compute **CrossEntropyLoss** (frame-wise)\n",
    "* Backprop + optimizer step\n",
    "* Save checkpoint per epoch\n",
    "\n",
    "**Code written in:**\n",
    "\n",
    "* `src/training/train.py`\n",
    "* `src/training/optimizer.py`\n",
    "* `src/training/scheduler.py`\n",
    "\n",
    "**Output (artifacts):**\n",
    "\n",
    "* `outputs/checkpoints/model_epoch_*.pt`\n",
    "* `outputs/checkpoints/logs/train.log`\n",
    "\n",
    "**Validation check:**\n",
    "\n",
    "* Training loss decreases across epochs\n",
    "\n",
    "---\n",
    "\n",
    "## **STEP 8 — INFERENCE (FRAME PREDICTION)**\n",
    "\n",
    "**PURPOSE:** Predict frame labels from a trained model.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "* `data/processed/features/{sample_id}.npy`\n",
    "* `outputs/checkpoints/model_epoch_*.pt`\n",
    "\n",
    "**Process:**\n",
    "\n",
    "* Run model forward\n",
    "* Get `argmax` class per frame\n",
    "\n",
    "**Code written in:**\n",
    "\n",
    "* `src/inference/predict_frames.py`\n",
    "\n",
    "**Output (artifact):**\n",
    "\n",
    "* `outputs/predictions/frame_preds_{sample_id}.npy` *(shape: T)*\n",
    "\n",
    "**Validation check:**\n",
    "\n",
    "* Prediction length matches feature frames `T`\n",
    "\n",
    "---\n",
    "\n",
    "## **STEP 9 — WORD TIMESTAMP EXTRACTION**\n",
    "\n",
    "**PURPOSE:** Convert frame predictions into word start/end timestamps.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "* `frame_preds_{sample_id}.npy`\n",
    "* hop_length, sample_rate\n",
    "\n",
    "**Process:**\n",
    "\n",
    "* Merge consecutive same-label frames\n",
    "* Ignore BLANK segments\n",
    "* Convert frames → seconds\n",
    "\n",
    "**Code written in:**\n",
    "\n",
    "* `src/inference/word_timestamp_extractor.py`\n",
    "* `src/inference/timestamp_extractor.py`\n",
    "\n",
    "**Output (artifact):**\n",
    "\n",
    "* `outputs/predictions/aligned_words.json`\n",
    "  Format:\n",
    "\n",
    "  ```json\n",
    "  [{\"word\":\"CLOSE\",\"start_time\":0.28,\"end_time\":0.76}]\n",
    "  ```\n",
    "\n",
    "**Validation check:**\n",
    "\n",
    "* Start/end times are within audio duration\n",
    "\n",
    "---\n",
    "\n",
    "## **STEP 10 — EVALUATION**\n",
    "\n",
    "**PURPOSE:** Measure timestamp accuracy against ground-truth annotations.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "* `outputs/predictions/aligned_words.json`\n",
    "* `data/raw/annotations/{sample_id}_Annotated.txt`\n",
    "\n",
    "**Process:**\n",
    "\n",
    "* Compare predicted vs true word timestamps\n",
    "* Compute mean/median deviation\n",
    "\n",
    "**Code written in:**\n",
    "\n",
    "* `src/evaluation/alignment_metrics.py`\n",
    "\n",
    "**Output (artifact):**\n",
    "\n",
    "* `outputs/predictions/eval_report.json` *(or printed report)*\n",
    "\n",
    "**Validation check:**\n",
    "\n",
    "* Metrics run without errors and produce numeric results\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ END-TO-END EXECUTION (Scripts)\n",
    "\n",
    "* `scripts/preprocess.py` → runs Steps **1–4**\n",
    "* `scripts/train.py` → runs Step **7**\n",
    "* `scripts/infer_alignment.py` → runs Steps **8–9**\n",
    "* `scripts/evaluate.py` → runs Step **10**\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
